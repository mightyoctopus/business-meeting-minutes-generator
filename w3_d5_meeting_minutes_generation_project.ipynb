{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMV6FkwC7o9uU/0JJJVSO9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mightyoctopus/business-meeting-minutes-generator/blob/main/w3_d5_meeting_minutes_generation_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVwYTRtmf-4d"
      },
      "outputs": [],
      "source": [
        "!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, threading\n",
        "import requests\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import drive, userdata\n",
        "from huggingface_hub import login, snapshot_download\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TextIteratorStreamer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "import torch"
      ],
      "metadata": {
        "id": "Wkg-Z0qFg2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_path = \"/content/drive/MyDrive/Colab Notebooks/huggingface_cache\""
      ],
      "metadata": {
        "id": "iUh1ryyt9aNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_MODEL = \"whisper-1\"\n",
        "LLAMA = \"meta-llama/Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "D14YqLhdhuSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Enables faster downloads using the Rust-based accelorated file transfer\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ],
      "metadata": {
        "id": "dCgnPlf2nawn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = snapshot_download(\n",
        "    repo_id=LLAMA,\n",
        "    cache_dir=cache_path,$\n",
        "    local_dir_use_symlinks=False,\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Absqv_5096ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Connect this Colab to Google Drive\n",
        "drive.mount(\"/content/drive1\", force_remount=True)\n",
        "# audio_filename = \"/content/drive1/MyDrive/Colab Notebooks/audio_data/Meeting_Record/Special Meeting Audio File - April 29, 2025.mp3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s564uFKtiPFo",
        "outputId": "0f801a27-d7c4-452e-ba01-c698a470ec79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "login(hf_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "6DHobJofl7Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "openai = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "vX_jg-UumRIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Use the Whisper model to convert the Audio to Text\n",
        "def transcribe_audio(audio_file):\n",
        "    with open(audio_file, \"rb\") as f:\n",
        "      transcription = openai.audio.transcriptions.create(\n",
        "          file=f,\n",
        "          model=AUDIO_MODEL,\n",
        "          temperature=0.1,\n",
        "          response_format=\"text\"\n",
        "      )\n",
        "    return transcription"
      ],
      "metadata": {
        "id": "61ALIWSjyXhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def use_messages(transcript):\n",
        "    system_message = \"\"\"\n",
        "      You're an assistant that produces meetings of minutes from transcripts\n",
        "      with a summary, key discussion points, takeaways and action items\n",
        "      with owners in markdown.\n",
        "      \"\"\"\n",
        "    user_prompt = f\"\"\"\n",
        "      Below is an extracted transcript of a Denver council meeting.\n",
        "      Please write minutes in markdown, including a summary with attendees,\n",
        "      location and date, discussion points, takeaways, and action items with owners.\n",
        "\n",
        "      transcript: {transcript}\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "    return messages"
      ],
      "metadata": {
        "id": "Nn6s-Z725miI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### load model/tokenizer ONCE (faster processing on click)\n",
        "### Not include in the stream_minutes function -- mistake\n",
        "bnb_quant_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_path,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=bnb_quant_config\n",
        "    )\n"
      ],
      "metadata": {
        "id": "iJJoA-kHbck0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_minutes(messages):\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        return_tensors=\"pt\",\n",
        "        tokenize=True\n",
        "    ).to(model.device)\n",
        "\n",
        "    streamer = TextIteratorStreamer(\n",
        "        tokenizer,\n",
        "        skip_prompt=True,\n",
        "        skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    gen_kwargs = dict(\n",
        "        inputs=inputs,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=2000\n",
        "    )\n",
        "\n",
        "    ### Run generation in background so it can iterate the streamer\n",
        "    t = threading.Thread(target=model.generate, kwargs=gen_kwargs)\n",
        "    t.start()\n",
        "\n",
        "    partial = \"\"\n",
        "    for chunk in streamer:\n",
        "        partial += chunk\n",
        "        yield partial  ### Gradio will live-update in the Textbox"
      ],
      "metadata": {
        "id": "zo3rUMxT7bW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "import gradio as gr\n",
        "import traceback"
      ],
      "metadata": {
        "id": "lEpZpJpgBv8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Gradio Progress bar(track_tqdm) used\n",
        "def process_audio_to_text(audio):\n",
        "    if not audio:\n",
        "        yield \"No audio file uploaded.\"\n",
        "        return\n",
        "\n",
        "    yield \"**Processing...**\\n_Transcribing the mp3 file and generating minutes, please wait._\\n\"\n",
        "\n",
        "    transcript = transcribe_audio(audio)\n",
        "    messages = use_messages(transcript)\n",
        "\n",
        "    # stream straight through / LLM streaming\n",
        "    header = \"**Transcription complete!**\\n\\n\"\n",
        "    for partial in stream_minutes(messages):\n",
        "        yield header + partial\n",
        "\n",
        "\n",
        "### --- Gradio UI --- ###\n",
        "with gr.Blocks(title=\"Minutes of Meeting Generator\", css=\"footer {visibility: hidden}\") as ui:\n",
        "    gr.HTML(\"<h1 style='text-align:center'>Minutes of Meeting Generator</h1>\")\n",
        "    audio = gr.Audio(sources=[\"upload\"], type=\"filepath\", label=\"Upload an MP3 file\")\n",
        "    btn = gr.Button(\"Transcribe\")\n",
        "    out = gr.Markdown(label=\"Result might take a couple of minutes to appear, processing a large mp3 file and transcribing.\")\n",
        "\n",
        "    # If fn yields strings, Gradio streams them\n",
        "    btn.click(process_audio_to_text, inputs=audio, outputs=out)\n",
        "    ui.queue()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ui.launch()"
      ],
      "metadata": {
        "id": "hiZpNZXDCDqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep -E 'torch|transformers|bitsandbytes|gradio|huggingface_hub|sentencepiece|accelerate|openai' > requirements.txt"
      ],
      "metadata": {
        "id": "9nNFMVxFsciK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .gitignore\n",
        "# Ignore Python cache and virtual environment stuff\n",
        "__pycache__/\n",
        "*.py[cod]\n",
        "*.pyo\n",
        "*.pyd\n",
        "*.so\n",
        "\n",
        "# Ignore notebook checkpoints\n",
        ".ipynb_checkpoints/\n",
        "\n",
        "# Ignore system & OS files\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "\n",
        "# Ignore virtual env folders\n",
        "env/\n",
        "venv/\n",
        "\n",
        "# Ignore Google Colab and Google Drive mounts\n",
        "/content/drive/\n",
        "drive/\n",
        "drive1/\n",
        "\n",
        "# Ignore token and secret files\n",
        "*.env\n",
        "*.secret\n",
        "*.key\n",
        "\n",
        "# Ignore HuggingFace and OpenAI cache\n",
        "~/.cache/\n",
        "huggingface/"
      ],
      "metadata": {
        "id": "Fd7rKLHJvmVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**To view the HF Spaces deployed version, check this code:**\n",
        "https://github.com/mightyoctopus/business-meeting-minutes-generator/blob/main/app.py\n",
        "\n",
        "**or check this file:**\n",
        "https://gist.github.com/mightyoctopus/cab59260d75bc85dc6133092edbf1d36\n"
      ],
      "metadata": {
        "id": "ikXEYyTdIqpg"
      }
    }
  ]
}